{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousePricePrediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyj95TabpKhw0YULvDpiVR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aqib9393/HousePricePrediction-Saylani/blob/main/HousePricePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPMh8q-vonVQ",
        "outputId": "81519004-b52d-4bdd-a499-c74ea667d0ec"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Jxu6PHopCI"
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Vr2QVZotEn"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "def build_model():\n",
        " # Because we will need to instantiate\n",
        " # the same model multiple time,\n",
        " # we use a function to construct it.\n",
        " model = models.Sequential()\n",
        " model.add(layers.Dense(64, activation='relu',\n",
        " input_shape=(train_data.shape[1],)))\n",
        " model.add(layers.Dense(64, activation='relu'))\n",
        " model.add(layers.Dense(1))\n",
        " model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        " return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93lPA2Qhotqn",
        "outputId": "1b832cbe-3e42-422b-8fe9-fcac7be9c64f"
      },
      "source": [
        "import numpy as np\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        " print('processing fold #', i)\n",
        " # Prepare the validation data: data from partition # k\n",
        " val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " # Prepare the training data: data from all other partitions\n",
        " partial_train_data = np.concatenate(\n",
        " [train_data[:i * num_val_samples],\n",
        " train_data[(i + 1) * num_val_samples:]],\n",
        " axis=0)\n",
        " partial_train_targets = np.concatenate(\n",
        " [train_targets[:i * num_val_samples],\n",
        " train_targets[(i + 1) * num_val_samples:]],\n",
        " axis=0)\n",
        " # Build the Keras model (already compiled)\n",
        " model = build_model()\n",
        " # Train the model (in silent mode, verbose=0)\n",
        " model.fit(partial_train_data, partial_train_targets,\n",
        " epochs=num_epochs, batch_size=1, verbose=0)\n",
        " # Evaluate the model on the validation data\n",
        " val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        " all_scores.append(val_mae)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwb8PaBGov3v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}